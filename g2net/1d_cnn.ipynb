{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import tensorflow as tf  # for reading TFRecord Dataset\n",
    "import tensorflow_datasets as tfds  # for making tf.data.Dataset to return numpy arrays\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TFRecord Loader\n",
    "train_gcs_paths = [\n",
    "    \"gs://kds-68dcd9850ea61ccbd6899e8c2e96fdac52b1b7b779d4ca58caca272e\",\n",
    "    \"gs://kds-3232b2fd9a72814c605032010853239f477f398aeae2448327ce82dd\",\n",
    "    \"gs://kds-08b564b271d72b224e01986c7f62bb7bb5b595df73a10242a6881d6c\",\n",
    "    \"gs://kds-c25102ee23417a87f8dfd5828737dc97c3be9c783200bef681528fe9\",\n",
    "]\n",
    "test_gcs_paths = [\n",
    "    \"gs://kds-3af0f2c792ef9e6f5d3c87bb80c99a263fc9707106cd595aaf02e3eb\",\n",
    "    \"gs://kds-9eb3135b732342c0aec8339381fec9fd19f8a7ad94ca9c31ad51fe2b\",\n",
    "]\n",
    "\n",
    "def to_numpy_array(gcs_paths):\n",
    "    all_files = [\n",
    "        x\n",
    "        for _ in gcs_paths\n",
    "        for x in np.sort(np.array(tf.io.gfile.glob(_ + \"/train*.tfrecords\")))\n",
    "    ]\n",
    "    if len(all_files) == 0:\n",
    "        raise RuntimeError(\"Empty gcs file paths\")\n",
    "    return np.array(all_files)\n",
    "\n",
    "all_train_files = to_numpy_array(train_gcs_paths)\n",
    "print(\"train_files: \", len(all_train_files))\n",
    "all_test_files = to_numpy_array(test_gcs_paths)\n",
    "print(\"test_files: \", len(all_test_files))\n",
    "\n",
    "SAVEDIR = Path(\"./\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Start time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "datetime.now(timezone(timedelta(hours=+9), \"JST\")).strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "\n",
    "gpu_info_raw = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info_raw)\n",
    "print('Not connected to a GPU' if gpu_info.find('failed') >= 0 else gpu_info)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    debug = False\n",
    "    print_freq = 2500\n",
    "    num_workers = 4\n",
    "    scheduler = \"CosineAnnealingLR\"\n",
    "    model_name = \"1dcnn\"\n",
    "    epochs = 8\n",
    "    T_max = 5\n",
    "    lr = 1e-4\n",
    "    min_lr = 1e-7\n",
    "    batch_size = 50\n",
    "    val_batch_size = 100\n",
    "    weight_decay = 1e-5\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "    factor = 0.2\n",
    "    patience = 1\n",
    "    eps = 1e-7\n",
    "    seed = 1127802825\n",
    "    target_size = 1\n",
    "    target_col = \"target\"\n",
    "    n_fold = 5\n",
    "    trn_fold = [0, 1, 2, 3, 4]\n",
    "    train = True\n",
    "    bandpass_params = dict(lf=25, hf=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Utils\n",
    "def get_score(y_true, y_pred):\n",
    "    score = roc_auc_score(y_true, y_pred)\n",
    "    return score\n",
    "\n",
    "def init_logger(log_file=SAVEDIR / 'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    \"\"\"\n",
    "    Util method\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def count_data_items(file_ids, train=True):\n",
    "    \"\"\"\n",
    "    Count the number of samples.\n",
    "    Each of the TFRecord datasets is designed to contain 28000 samples for train\n",
    "    22500 for test.\n",
    "    \"\"\"\n",
    "    sizes = 28000 if train else 22500\n",
    "    return len(file_ids) * sizes\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Bandpass\n",
    "def bandpass(x, lf=20, hf=500, order=8, sr=2048):\n",
    "    sos = signal.butter(order, [lf, hf], btype=\"bandpass\", output=\"sos\", fs=sr)\n",
    "    normalization = np.sqrt((hf - lf) / (sr / 2))\n",
    "    window = signal.tukey(4096, 0.1)\n",
    "    if x.ndim == 2:\n",
    "        x *= window\n",
    "        for i in range(3):\n",
    "            x[i] = signal.sosfilt(sos, x[i]) * normalization\n",
    "    elif x.ndim == 3: # batch\n",
    "        for i in range(x.shape[0]):\n",
    "            x[i] *= window\n",
    "            for j in range(3):\n",
    "                x[i, j] = signal.sosfilt(sos, x[i, j]) * normalization\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prepare_wave(wave):\n",
    "    wave = tf.reshape(tf.io.decode_raw(wave, tf.float64), (3, 4096))\n",
    "    normalized_waves = []\n",
    "    scaling = tf.constant([1.5e-20, 1.5e-20, 0.5e-20], dtype=tf.float64)\n",
    "    for i in range(3):\n",
    "        #         normalized_wave = wave[i] / tf.math.reduce_max(wave[i])\n",
    "        normalized_wave = wave[i] / scaling[i]\n",
    "        normalized_waves.append(normalized_wave)\n",
    "    wave = tf.stack(normalized_waves, axis=0)\n",
    "    wave = tf.cast(wave, tf.float32)\n",
    "    return wave\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    tfrec_format = {\n",
    "        \"wave\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"wave_id\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return prepare_wave(example[\"wave\"]), tf.reshape(tf.cast(example[\"target\"], tf.float32), [1]), example[\"wave_id\"]\n",
    "\n",
    "def read_unlabeled_tfrecord(example, return_image_id):\n",
    "    tfrec_format = {\n",
    "        \"wave\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"wave_id\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return prepare_wave(example[\"wave\"]), example[\"wave_id\"] if return_image_id else 0\n",
    "\n",
    "def get_dataset(files, batch_size=16, repeat=False, cache=False,\n",
    "                shuffle=False, labeled=True, return_image_ids=True):\n",
    "    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO, compression_type=\"GZIP\")\n",
    "    if cache:\n",
    "        # You'll need around 15GB RAM if you'd like to cache val dataset, and 50~60GB RAM for train dataset.\n",
    "        ds = ds.cache()\n",
    "\n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1024 * 2)\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        ds = ds.with_options(opt)\n",
    "\n",
    "    if labeled:\n",
    "        ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    else:\n",
    "        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_ids), num_parallel_calls=AUTO)\n",
    "\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    return tfds.as_numpy(ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TFRecordDataLoader:\n",
    "    def __init__(self, files, batch_size=32, cache=False, train=True,\n",
    "                 repeat=False, shuffle=False, labeled=True,\n",
    "                 return_image_ids=True):\n",
    "        self.ds = get_dataset(\n",
    "            files,\n",
    "            batch_size=batch_size,\n",
    "            cache=cache,\n",
    "            repeat=repeat,\n",
    "            shuffle=shuffle,\n",
    "            labeled=labeled,\n",
    "            return_image_ids=return_image_ids)\n",
    "\n",
    "        self.num_examples = count_data_items(files, labeled)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.labeled = labeled\n",
    "        self.return_image_ids = return_image_ids\n",
    "        self._iterator = None\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self._iterator is None:\n",
    "            self._iterator = iter(self.ds)\n",
    "        else:\n",
    "            self._reset()\n",
    "        return self._iterator\n",
    "\n",
    "    def _reset(self):\n",
    "        self._iterator = iter(self.ds)\n",
    "\n",
    "    def __next__(self):\n",
    "        batch = next(self._iterator)\n",
    "        return batch\n",
    "\n",
    "    def __len__(self):\n",
    "        n_batches = self.num_examples // self.batch_size\n",
    "        if self.num_examples % self.batch_size == 0:\n",
    "            return n_batches\n",
    "        else:\n",
    "            return n_batches + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Model\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, kernel_size=8, p=3, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool1d(x.clamp(min=eps).pow(p), self.kernel_size).pow(1./p)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \\\n",
    "               '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
    "               ', ' + 'eps=' + str(self.eps) + ')'\n",
    "\n",
    "\n",
    "class CNN1d(nn.Module):\n",
    "    def __init__(self, debug=False):\n",
    "        super().__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv1d(3, 64, kernel_size=64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, kernel_size=32),\n",
    "            GeM(kernel_size=8),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "        self.cnn3 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=32),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "        self.cnn4 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, kernel_size=16),\n",
    "            GeM(kernel_size=6),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "        self.cnn5 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=16),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "        self.cnn6 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=16),\n",
    "            GeM(kernel_size=4),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(256 * 11, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(64, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "        self.debug = debug\n",
    "\n",
    "    def forward(self, x, pos=None):\n",
    "        x = self.cnn1(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = self.cnn3(x)\n",
    "        x = self.cnn4(x)\n",
    "        x = self.cnn5(x)\n",
    "        x = self.cnn6(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Helper\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / percent\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def max_memory_allocated():\n",
    "    MB = 1024.0 * 1024.0\n",
    "    mem = torch.cuda.max_memory_allocated() / MB\n",
    "    return f\"{mem:.0f} MB\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Trainer\n",
    "def train_fn(files, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "\n",
    "    train_loader = TFRecordDataLoader(\n",
    "        files, batch_size=CFG.batch_size,\n",
    "        shuffle=True)\n",
    "    for step, d in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        x = bandpass(d[0], **CFG.bandpass_params)\n",
    "        x = torch.from_numpy(x).to(device)\n",
    "        labels = torch.from_numpy(d[1]).to(device)\n",
    "\n",
    "        batch_size = labels.size(0)\n",
    "        y_preds = model(x)\n",
    "        loss = criterion(y_preds.view(-1), labels.view(-1))\n",
    "        # record loss\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0:\n",
    "            print('Epoch: [{0}/{1}][{2}/{3}] '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.6f}  '\n",
    "                  'Elapsed: {remain:s} '\n",
    "                  'Max mem: {mem:s}'\n",
    "                .format(\n",
    "                epoch+1, CFG.epochs, step, len(train_loader),\n",
    "                loss=losses,\n",
    "                grad_norm=grad_norm,\n",
    "                lr=scheduler.get_last_lr()[0],\n",
    "                remain=timeSince(start, float(step + 1) / len(train_loader)),\n",
    "                mem=max_memory_allocated()))\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(files, model, criterion, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    filenames = []\n",
    "    targets = []\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    valid_loader = TFRecordDataLoader(\n",
    "        files, batch_size=CFG.batch_size * 2, shuffle=False)\n",
    "    for step, d in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        targets.extend(d[1].reshape(-1).tolist())\n",
    "        filenames.extend([f.decode(\"UTF-8\") for f in d[2]])\n",
    "        x = bandpass(d[0], **CFG.bandpass_params)\n",
    "        x = torch.from_numpy(x).to(device)\n",
    "        labels = torch.from_numpy(d[1]).to(device)\n",
    "\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(x)\n",
    "        loss = criterion(y_preds.view(-1), labels.view(-1))\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0:\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                .format(\n",
    "                step, len(valid_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses,\n",
    "                remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "            ))\n",
    "    predictions = np.concatenate(preds).reshape(-1)\n",
    "    return losses.avg, predictions, np.array(targets), np.array(filenames)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train loop\n",
    "def train_loop(train_tfrecords: np.ndarray, val_tfrecords: np.ndarray, fold: int):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler == 'ReduceLROnPlateau':\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                             mode='max',\n",
    "                                                             factor=CFG.factor,\n",
    "                                                             patience=CFG.patience,\n",
    "                                                             verbose=True,\n",
    "                                                             eps=CFG.eps)\n",
    "        elif CFG.scheduler == 'CosineAnnealingLR':\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                             T_max=CFG.T_max,\n",
    "                                                             eta_min=CFG.min_lr,\n",
    "                                                             last_epoch=-1)\n",
    "        elif CFG.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer,\n",
    "                                                                       T_0=CFG.T_0,\n",
    "                                                                       T_mult=1,\n",
    "                                                                       eta_min=CFG.min_lr,\n",
    "                                                                       last_epoch=-1)\n",
    "        else:\n",
    "            raise RuntimeError(\"No CFB.scheduler match\")\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CNN1d()\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_score = 0.\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        print(\"\\n\\n\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(train_tfrecords, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds, targets, files = valid_fn(val_tfrecords, model, criterion, device)\n",
    "        valid_result_df = pd.DataFrame({\"target\": targets, \"preds\": preds, \"id\": files})\n",
    "\n",
    "        if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, optim.lr_scheduler.CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(targets, preds)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'preds': preds},\n",
    "                       SAVEDIR / f'{CFG.model_name}_fold{fold}_best_score.pth')\n",
    "\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'preds': preds},\n",
    "                       SAVEDIR / f'{CFG.model_name}_fold{fold}_best_loss.pth')\n",
    "\n",
    "    valid_result_df[\"preds\"] = torch.load(SAVEDIR / f\"{CFG.model_name}_fold{fold}_best_loss.pth\",\n",
    "                                          map_location=\"cpu\")[\"preds\"]\n",
    "\n",
    "    return valid_result_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_result(result_df):\n",
    "    preds = result_df['preds'].values\n",
    "    labels = result_df[CFG.target_col].values\n",
    "    score = get_score(labels, preds)\n",
    "    LOGGER.info(f'Score: {score:<.4f}')\n",
    "\n",
    "if CFG.train:\n",
    "    # train\n",
    "    oof_df = pd.DataFrame()\n",
    "    kf = KFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "    folds = list(kf.split(all_train_files))\n",
    "    for fold in range(CFG.n_fold):\n",
    "        if fold in CFG.trn_fold:\n",
    "            trn_idx, val_idx = folds[fold]\n",
    "            train_files = all_train_files[trn_idx]\n",
    "            valid_files = all_train_files[val_idx]\n",
    "            _oof_df = train_loop(train_files, valid_files, fold)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "            get_result(_oof_df)\n",
    "            # 再開用のデータを保存\n",
    "            oof_df.to_csv(SAVEDIR / f\"oof_df_fold{fold}.csv\", index=False)\n",
    "    # CV result\n",
    "    LOGGER.info(f\"========== CV ==========\")\n",
    "    get_result(oof_df)\n",
    "    # save result\n",
    "    oof_df.to_csv(SAVEDIR / 'oof_df.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Inference\n",
    "states = []\n",
    "for fold  in CFG.trn_fold:\n",
    "    states.append(torch.load(os.path.join(SAVEDIR, f'{CFG.model_name}_fold{fold}_best_score.pth')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model= CNN1d()\n",
    "model.to(device)\n",
    "\n",
    "wave_ids = []\n",
    "probs_all = []\n",
    "\n",
    "for fold, state in enumerate(states):\n",
    "\n",
    "    model.load_state_dict(state['model'])\n",
    "    model.eval()\n",
    "    probs = []\n",
    "\n",
    "    test_loader = TFRecordDataLoader(all_test_files, batch_size=CFG.val_batch_size,\n",
    "                                     shuffle=False, labeled=False)\n",
    "\n",
    "    for i, d in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "        x = bandpass(d[0], **CFG.bandpass_params)\n",
    "        x = torch.from_numpy(x).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(x)\n",
    "        preds = y_preds.sigmoid().to('cpu').numpy()\n",
    "        probs.append(preds)\n",
    "\n",
    "        if fold == 0:  # same test loader, no need to do this the second time\n",
    "            wave_ids.append(d[1].astype('U13'))\n",
    "\n",
    "    probs = np.concatenate(probs)\n",
    "    probs_all.append(probs)\n",
    "\n",
    "probs_avg = np.asarray(probs_all).mean(axis=0).flatten()\n",
    "wave_ids = np.concatenate(wave_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'id': wave_ids, 'target': probs_avg})\n",
    "# Save test dataframe to disk\n",
    "folds = '_'.join([str(s) for s in CFG.trn_fold])\n",
    "test_df.to_csv(f'{CFG.model_name}_folds_{folds}.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}